{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8fad6969b9004d2d9966282740b05f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306ce91ba7b04a4ea566664ba904bd1e",
              "IPY_MODEL_9705686408014dcea8d76d6bc1edecef",
              "IPY_MODEL_1bb4fd4c488c46ef806014b0408f197b"
            ],
            "layout": "IPY_MODEL_19355a31f6b544718c89923cc5b3d7d0"
          }
        },
        "306ce91ba7b04a4ea566664ba904bd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_550f033d79eb416d8d4dcff059b43018",
            "placeholder": "​",
            "style": "IPY_MODEL_640dc31b17f14d94b15c94ceaac34c57",
            "value": "Map: 100%"
          }
        },
        "9705686408014dcea8d76d6bc1edecef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a24dceb6e4d1413eb978b3f997ee1af5",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d4352bf04cf46ddbd87987ae6611d8e",
            "value": 10
          }
        },
        "1bb4fd4c488c46ef806014b0408f197b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c720632aa534e5f9a0360eebbe03c53",
            "placeholder": "​",
            "style": "IPY_MODEL_d6bb789de7304fd99934492df31e2ea7",
            "value": " 10/10 [00:00&lt;00:00, 117.49 examples/s]"
          }
        },
        "19355a31f6b544718c89923cc5b3d7d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550f033d79eb416d8d4dcff059b43018": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "640dc31b17f14d94b15c94ceaac34c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a24dceb6e4d1413eb978b3f997ee1af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4352bf04cf46ddbd87987ae6611d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c720632aa534e5f9a0360eebbe03c53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6bb789de7304fd99934492df31e2ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JWu5wDAjmzo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a896d19-348f-4cee-bcdf-a673866cff8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL ALL THE DEPENDENCIES !"
      ],
      "metadata": {
        "id": "et8WEH2RdtiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "\n",
        "!pip uninstall google-cloud-storage numpy\n",
        "\n",
        "!pip install google-cloud-storage==2.10.0\n",
        "!pip install numpy==1.26.4\n",
        "\n",
        "!pip install transformers datasets torch evaluate scikit-learn flask joblib mlflow peft accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "TnL2_Dxhw_kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT ALL THE REQUIRED LIBRARIES"
      ],
      "metadata": {
        "id": "e30JLWe0d0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict\n",
        "import evaluate\n",
        "import os"
      ],
      "metadata": {
        "id": "DTYMIlm30ceF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAIN CODE"
      ],
      "metadata": {
        "id": "gVZpFcgVd32g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Small Custom Dataset\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"The system detected a possible intrusion attempt.\",\n",
        "        \"User logged in successfully.\",\n",
        "        \"Suspicious network activity was observed.\",\n",
        "        \"Firewall blocked a malicious request.\",\n",
        "        \"Normal system operation detected.\",\n",
        "        \"Unauthorized access attempt detected.\",\n",
        "        \"Routine maintenance activity logged.\",\n",
        "        \"Malware detected in the downloaded file.\",\n",
        "        \"User logged out without issues.\",\n",
        "        \"Anomaly detected in login behavior.\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 1, 0, 1, 0, 1, 0, 1]  # 1 = Threat, 0 = Normal\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "# Load a Small Model & Tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Add Padding Token\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "model.resize_token_embeddings(len(tokenizer))  # Resize embeddings\n",
        "\n",
        "# Tokenization Function\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Split Dataset into Train & Test\n",
        "split_data = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = split_data[\"train\"]\n",
        "test_dataset = split_data[\"test\"]\n",
        "\n",
        "# Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "# Define Accuracy Metric\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Train the Model**\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Disable Weights & Biases logging\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Save the Model\n",
        "model.save_pretrained(\"./fine_tuned_model\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_model\")\n",
        "\n",
        "# Detect the available device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move model to the same device\n",
        "model.to(device)\n",
        "\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}  # Move input tensors to the correct device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)  # Ensure inference runs on the same device\n",
        "    prediction = torch.argmax(outputs.logits).item()\n",
        "    return \"Threat\" if prediction == 1 else \"Normal\"\n",
        "\n",
        "# Test Inference\n",
        "sample_text = \"Unusual login attempt detected from a foreign country.\"\n",
        "print(f\"Prediction: {predict(sample_text)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409,
          "referenced_widgets": [
            "8fad6969b9004d2d9966282740b05f2b",
            "306ce91ba7b04a4ea566664ba904bd1e",
            "9705686408014dcea8d76d6bc1edecef",
            "1bb4fd4c488c46ef806014b0408f197b",
            "19355a31f6b544718c89923cc5b3d7d0",
            "550f033d79eb416d8d4dcff059b43018",
            "640dc31b17f14d94b15c94ceaac34c57",
            "a24dceb6e4d1413eb978b3f997ee1af5",
            "7d4352bf04cf46ddbd87987ae6611d8e",
            "8c720632aa534e5f9a0360eebbe03c53",
            "d6bb789de7304fd99934492df31e2ea7"
          ]
        },
        "id": "JziySfSa0fTh",
        "outputId": "ed919ddd-a8f9-4728-f997-f16fd48f61d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fad6969b9004d2d9966282740b05f2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "2025/03/23 06:18:48 ERROR mlflow.utils.async_logging.async_logging_queue: Run Id 29699817ea714ee2a57f4f0b9aab3951: Failed to log run data: Exception: Changing param values is not allowed. Param with key='report_to' was already logged with value='['mlflow', 'tensorboard', 'wandb']' for run ID='29699817ea714ee2a57f4f0b9aab3951'. Attempted logging new value '['mlflow', 'tensorboard']'.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:42, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.669809</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.662132</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.652689</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.642626</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.637269</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Threat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL FLASK AND NGROK\n",
        "\n",
        "- We cannoyt test flask api's in Colab, to do so use ngrok\n",
        "- Create your account in https://ngrok.com/\n",
        "- Go to your dashboard in ngrok and copy the \"Your Authtoken\""
      ],
      "metadata": {
        "id": "KWQAGm8weEHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask flask-tunnel transformers torch\n",
        "!pip install flask flask-ngrok transformers torch"
      ],
      "metadata": {
        "id": "pZrHpJqGDFS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken \"Your Authtoken\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzHfAz6sEHCx",
        "outputId": "e8eb2396-61ab-4e7b-fc3e-7cd9ec6b72a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4yLV2l9FBDB",
        "outputId": "bdc9af1c-8fce-41b7-9921-a41a5bdc1762"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken \"Your Authtoken\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr7N0TzzG8Xp",
        "outputId": "90896c71-7a52-4193-e367-161e6b463bbc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLASK API"
      ],
      "metadata": {
        "id": "DIL2Jb_ier4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load fine-tuned model\n",
        "MODEL_PATH = \"./fine_tuned_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    if \"text\" not in data:\n",
        "        return jsonify({\"error\": \"Missing 'text' field\"}), 400\n",
        "\n",
        "    text = data[\"text\"]\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    prediction = torch.argmax(outputs.logits).item()\n",
        "    label = \"Threat\" if prediction == 1 else \"Normal\"\n",
        "\n",
        "    return jsonify({\"prediction\": label})\n",
        "\n",
        "# Start Flask in a separate thread\n",
        "def run_flask():\n",
        "    app.run(host=\"0.0.0.0\", port=5000)\n",
        "\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n",
        "# Open an ngrok tunnel to the Flask server\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"🌍 Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6Ud2DhKHBZ0",
        "outputId": "ebba2539-956b-4dff-f180-25c217d706bd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌍 Public URL: https://8ae7-34-87-158-193.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST THE FLASK API"
      ],
      "metadata": {
        "id": "ApMuZ_SRewCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "BASE_URL = \"http://127.0.0.1:5000\"  # Replace with the printed URL\n",
        "\n",
        "data = {\"text\": \"Unauthorized access attempt detected\"}\n",
        "response = requests.post(f\"{BASE_URL}/predict\", json=data)\n",
        "\n",
        "print(\"Status Code:\", response.status_code)\n",
        "print(\"Response JSON:\", response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny5WAkaSHLkO",
        "outputId": "89df4f21-e765-484a-cded-6fe7cc65a3e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [23/Mar/2025 06:21:39] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Response JSON: {'prediction': 'Threat'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ZIP THE FINE TUNED MODEL & DOWNLOAD IT TO YOUR LOCAL SYSTEM"
      ],
      "metadata": {
        "id": "9eFpoo8ue3he"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fine_tuned_model.zip ./fine_tuned_model/\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"fine_tuned_model.zip\")"
      ],
      "metadata": {
        "id": "ur_-RsEDthwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}